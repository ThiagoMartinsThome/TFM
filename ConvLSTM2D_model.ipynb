{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ConvLSTM2D_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1vsaY59aqNnwSm7OeiDVHNNctJJ2MQWce",
      "authorship_tag": "ABX9TyMApedGEnMoqd3CZwt7ErjM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ThiagoMartinsThome/TFM/blob/master/ConvLSTM2D_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AeVT95cMrjsu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "import math\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Bidirectional\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import TimeDistributed, RepeatVector\n",
        "from tensorflow.keras.layers import Activation, MaxPool3D\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import ConvLSTM2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler, QuantileTransformer, PowerTransformer\n",
        "from sklearn.metrics import mean_squared_error , mean_absolute_error, r2_score\n",
        "from sklearn.decomposition import PCA\n",
        "import joblib\n",
        "rcParams['figure.figsize'] = 16, 8\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g14jZtS5u1ZP",
        "colab_type": "text"
      },
      "source": [
        "## Load and prepare the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRmGCjV7vfok",
        "colab_type": "text"
      },
      "source": [
        "#### Load the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VYqUevFvd1p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500
        },
        "outputId": "59e9324d-8e4a-4ad7-be48-c087b6248419"
      },
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/TFM/tradebot_tfm/data_20day_chg_target.zip', parse_dates=['date'])\n",
        "\n",
        "# load data\n",
        "data = df.copy()\n",
        "data.drop('long_name', axis=1, inplace=True)\n",
        "data.dropna(inplace=True, axis=0)\n",
        "data.sort_values(by=['ticker', 'date'], ascending=True, inplace=True)\n",
        "data.set_index('date', inplace=True)\n",
        "\n",
        "print('Null values: ', data.isnull().sum().sum())\n",
        "\n",
        "data.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Null values:  0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ticker</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>sp_open</th>\n",
              "      <th>sp_high</th>\n",
              "      <th>sp_low</th>\n",
              "      <th>sp_close</th>\n",
              "      <th>sp_volume</th>\n",
              "      <th>sp_percent_change</th>\n",
              "      <th>percent_change</th>\n",
              "      <th>relative_change</th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>day_of_year</th>\n",
              "      <th>week_of_year</th>\n",
              "      <th>quarter</th>\n",
              "      <th>f_14_period_rsi</th>\n",
              "      <th>f_14_period_stoch_k</th>\n",
              "      <th>f_20_period_cci</th>\n",
              "      <th>up_move</th>\n",
              "      <th>down_move</th>\n",
              "      <th>plus</th>\n",
              "      <th>minus</th>\n",
              "      <th>f_14_period_adx</th>\n",
              "      <th>diplus</th>\n",
              "      <th>diminus</th>\n",
              "      <th>ao</th>\n",
              "      <th>mom</th>\n",
              "      <th>macd</th>\n",
              "      <th>signal_x</th>\n",
              "      <th>f_14_period_stochastic_rsi</th>\n",
              "      <th>f_14_williams_r</th>\n",
              "      <th>bull</th>\n",
              "      <th>bear</th>\n",
              "      <th>uo</th>\n",
              "      <th>f_8_period_vama</th>\n",
              "      <th>deltawma</th>\n",
              "      <th>f_16_period_hma</th>\n",
              "      <th>tenkan</th>\n",
              "      <th>kijun</th>\n",
              "      <th>f_9_period_smm</th>\n",
              "      <th>f_9_period_ssma</th>\n",
              "      <th>f_9_period_dema</th>\n",
              "      <th>f_9_period_tema</th>\n",
              "      <th>f_18_period_trima</th>\n",
              "      <th>f_20_period_trix</th>\n",
              "      <th>f_10_period_er</th>\n",
              "      <th>f_20_period_kama</th>\n",
              "      <th>f_26_period_zlema</th>\n",
              "      <th>f_9_period_wma</th>\n",
              "      <th>f_20_period_evwma</th>\n",
              "      <th>vwap</th>\n",
              "      <th>ppo</th>\n",
              "      <th>signal_y</th>\n",
              "      <th>histo</th>\n",
              "      <th>roc</th>\n",
              "      <th>f_5_period_sma</th>\n",
              "      <th>f_5_period_ema</th>\n",
              "      <th>f_10_period_sma</th>\n",
              "      <th>f_10_period_ema</th>\n",
              "      <th>f_20_period_sma</th>\n",
              "      <th>f_20_period_ema</th>\n",
              "      <th>f_30_period_sma</th>\n",
              "      <th>f_30_period_ema</th>\n",
              "      <th>f_50_period_sma</th>\n",
              "      <th>f_50_period_ema</th>\n",
              "      <th>f_100_period_sma</th>\n",
              "      <th>f_100_period_ema</th>\n",
              "      <th>f_200_period_sma</th>\n",
              "      <th>f_200_period_ema</th>\n",
              "      <th>short_result</th>\n",
              "      <th>sector</th>\n",
              "      <th>industry</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1993-11-11</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>0.921914</td>\n",
              "      <td>0.959390</td>\n",
              "      <td>0.914418</td>\n",
              "      <td>0.940652</td>\n",
              "      <td>35607600.0</td>\n",
              "      <td>28.214053</td>\n",
              "      <td>28.289897</td>\n",
              "      <td>28.119247</td>\n",
              "      <td>28.138208</td>\n",
              "      <td>88900</td>\n",
              "      <td>-0.002688</td>\n",
              "      <td>0.020325</td>\n",
              "      <td>0.023013</td>\n",
              "      <td>1993.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>315.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>60.349555</td>\n",
              "      <td>59.374851</td>\n",
              "      <td>43.972860</td>\n",
              "      <td>3.747602e-02</td>\n",
              "      <td>-1.499032e-02</td>\n",
              "      <td>0.037476</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>36.022545</td>\n",
              "      <td>29.416429</td>\n",
              "      <td>13.493711</td>\n",
              "      <td>0.102574</td>\n",
              "      <td>0.011243</td>\n",
              "      <td>0.039989</td>\n",
              "      <td>0.044281</td>\n",
              "      <td>0.599610</td>\n",
              "      <td>-40.625149</td>\n",
              "      <td>0.039216</td>\n",
              "      <td>-0.005756</td>\n",
              "      <td>55.330429</td>\n",
              "      <td>0.945870</td>\n",
              "      <td>0.931399</td>\n",
              "      <td>0.937907</td>\n",
              "      <td>0.937112</td>\n",
              "      <td>0.862096</td>\n",
              "      <td>0.944400</td>\n",
              "      <td>0.907955</td>\n",
              "      <td>0.942416</td>\n",
              "      <td>0.926890</td>\n",
              "      <td>0.826442</td>\n",
              "      <td>0.539938</td>\n",
              "      <td>0.050848</td>\n",
              "      <td>0.926042</td>\n",
              "      <td>0.967849</td>\n",
              "      <td>0.935405</td>\n",
              "      <td>0.862179</td>\n",
              "      <td>1.191158</td>\n",
              "      <td>4.528958</td>\n",
              "      <td>5.123036</td>\n",
              "      <td>-0.594078</td>\n",
              "      <td>5.462147</td>\n",
              "      <td>0.928659</td>\n",
              "      <td>0.931656</td>\n",
              "      <td>0.940652</td>\n",
              "      <td>0.927735</td>\n",
              "      <td>0.912732</td>\n",
              "      <td>0.898806</td>\n",
              "      <td>0.842089</td>\n",
              "      <td>0.874856</td>\n",
              "      <td>0.806337</td>\n",
              "      <td>0.862869</td>\n",
              "      <td>0.866003</td>\n",
              "      <td>0.927067</td>\n",
              "      <td>1.220093</td>\n",
              "      <td>1.040218</td>\n",
              "      <td>-10.0</td>\n",
              "      <td>Information Technology</td>\n",
              "      <td>Technology Hardware, Storage &amp; Peripherals</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1993-11-12</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>0.944399</td>\n",
              "      <td>0.959390</td>\n",
              "      <td>0.914418</td>\n",
              "      <td>0.951894</td>\n",
              "      <td>35915600.0</td>\n",
              "      <td>28.195089</td>\n",
              "      <td>28.365738</td>\n",
              "      <td>28.176128</td>\n",
              "      <td>28.270933</td>\n",
              "      <td>108200</td>\n",
              "      <td>0.004717</td>\n",
              "      <td>0.011952</td>\n",
              "      <td>0.007235</td>\n",
              "      <td>1993.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>316.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>61.832195</td>\n",
              "      <td>68.749683</td>\n",
              "      <td>44.949612</td>\n",
              "      <td>-1.787082e-07</td>\n",
              "      <td>1.703312e-07</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.703312e-07</td>\n",
              "      <td>36.100008</td>\n",
              "      <td>27.315254</td>\n",
              "      <td>12.529900</td>\n",
              "      <td>0.095344</td>\n",
              "      <td>0.029981</td>\n",
              "      <td>0.039336</td>\n",
              "      <td>0.043292</td>\n",
              "      <td>0.592462</td>\n",
              "      <td>-31.250317</td>\n",
              "      <td>0.034684</td>\n",
              "      <td>-0.010287</td>\n",
              "      <td>61.292067</td>\n",
              "      <td>0.941706</td>\n",
              "      <td>0.933083</td>\n",
              "      <td>0.933950</td>\n",
              "      <td>0.938361</td>\n",
              "      <td>0.871321</td>\n",
              "      <td>0.948147</td>\n",
              "      <td>0.912837</td>\n",
              "      <td>0.947884</td>\n",
              "      <td>0.936265</td>\n",
              "      <td>0.837211</td>\n",
              "      <td>0.554601</td>\n",
              "      <td>0.133332</td>\n",
              "      <td>0.926584</td>\n",
              "      <td>0.966667</td>\n",
              "      <td>0.937237</td>\n",
              "      <td>0.864885</td>\n",
              "      <td>1.190371</td>\n",
              "      <td>4.429322</td>\n",
              "      <td>4.984293</td>\n",
              "      <td>-0.554971</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.927910</td>\n",
              "      <td>0.938402</td>\n",
              "      <td>0.943650</td>\n",
              "      <td>0.932128</td>\n",
              "      <td>0.917979</td>\n",
              "      <td>0.903862</td>\n",
              "      <td>0.851084</td>\n",
              "      <td>0.879827</td>\n",
              "      <td>0.809935</td>\n",
              "      <td>0.866361</td>\n",
              "      <td>0.863433</td>\n",
              "      <td>0.927568</td>\n",
              "      <td>1.216010</td>\n",
              "      <td>1.039203</td>\n",
              "      <td>-7.0</td>\n",
              "      <td>Information Technology</td>\n",
              "      <td>Technology Hardware, Storage &amp; Peripherals</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1993-11-15</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>0.944400</td>\n",
              "      <td>0.981876</td>\n",
              "      <td>0.944400</td>\n",
              "      <td>0.959390</td>\n",
              "      <td>39275600.0</td>\n",
              "      <td>28.327813</td>\n",
              "      <td>28.327813</td>\n",
              "      <td>28.176124</td>\n",
              "      <td>28.251968</td>\n",
              "      <td>243300</td>\n",
              "      <td>-0.000671</td>\n",
              "      <td>0.007875</td>\n",
              "      <td>0.008546</td>\n",
              "      <td>1993.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>319.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>62.830174</td>\n",
              "      <td>69.231257</td>\n",
              "      <td>72.776436</td>\n",
              "      <td>2.248626e-02</td>\n",
              "      <td>-2.998154e-02</td>\n",
              "      <td>0.022486</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>36.561073</td>\n",
              "      <td>28.873022</td>\n",
              "      <td>11.634907</td>\n",
              "      <td>0.093602</td>\n",
              "      <td>0.014991</td>\n",
              "      <td>0.038973</td>\n",
              "      <td>0.042428</td>\n",
              "      <td>0.587757</td>\n",
              "      <td>-30.768743</td>\n",
              "      <td>0.052215</td>\n",
              "      <td>0.014739</td>\n",
              "      <td>55.698258</td>\n",
              "      <td>0.943250</td>\n",
              "      <td>0.939213</td>\n",
              "      <td>0.935329</td>\n",
              "      <td>0.938778</td>\n",
              "      <td>0.882131</td>\n",
              "      <td>0.948147</td>\n",
              "      <td>0.918009</td>\n",
              "      <td>0.954242</td>\n",
              "      <td>0.945976</td>\n",
              "      <td>0.848118</td>\n",
              "      <td>0.566746</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.926963</td>\n",
              "      <td>0.968349</td>\n",
              "      <td>0.940402</td>\n",
              "      <td>0.868122</td>\n",
              "      <td>1.189586</td>\n",
              "      <td>4.362565</td>\n",
              "      <td>4.859948</td>\n",
              "      <td>-0.497383</td>\n",
              "      <td>3.225861</td>\n",
              "      <td>0.935405</td>\n",
              "      <td>0.945398</td>\n",
              "      <td>0.945149</td>\n",
              "      <td>0.937085</td>\n",
              "      <td>0.923413</td>\n",
              "      <td>0.909151</td>\n",
              "      <td>0.860328</td>\n",
              "      <td>0.884960</td>\n",
              "      <td>0.813683</td>\n",
              "      <td>0.870011</td>\n",
              "      <td>0.860565</td>\n",
              "      <td>0.928209</td>\n",
              "      <td>1.211705</td>\n",
              "      <td>1.038288</td>\n",
              "      <td>-8.0</td>\n",
              "      <td>Information Technology</td>\n",
              "      <td>Technology Hardware, Storage &amp; Peripherals</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1993-11-16</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>0.959390</td>\n",
              "      <td>1.026847</td>\n",
              "      <td>0.951895</td>\n",
              "      <td>1.019352</td>\n",
              "      <td>75770800.0</td>\n",
              "      <td>28.308858</td>\n",
              "      <td>28.403664</td>\n",
              "      <td>28.195092</td>\n",
              "      <td>28.384703</td>\n",
              "      <td>492600</td>\n",
              "      <td>0.004698</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>0.057801</td>\n",
              "      <td>1993.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>320.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>69.663353</td>\n",
              "      <td>94.444463</td>\n",
              "      <td>131.443152</td>\n",
              "      <td>4.497108e-02</td>\n",
              "      <td>-7.494871e-03</td>\n",
              "      <td>0.044971</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>37.634356</td>\n",
              "      <td>33.828155</td>\n",
              "      <td>10.803841</td>\n",
              "      <td>0.100932</td>\n",
              "      <td>0.037476</td>\n",
              "      <td>0.043028</td>\n",
              "      <td>0.042548</td>\n",
              "      <td>0.583771</td>\n",
              "      <td>-5.555537</td>\n",
              "      <td>0.084373</td>\n",
              "      <td>0.009421</td>\n",
              "      <td>59.569664</td>\n",
              "      <td>0.957204</td>\n",
              "      <td>0.964699</td>\n",
              "      <td>0.947400</td>\n",
              "      <td>0.942109</td>\n",
              "      <td>0.893230</td>\n",
              "      <td>0.951894</td>\n",
              "      <td>0.929270</td>\n",
              "      <td>0.980103</td>\n",
              "      <td>0.981341</td>\n",
              "      <td>0.858864</td>\n",
              "      <td>0.582450</td>\n",
              "      <td>0.161291</td>\n",
              "      <td>0.929377</td>\n",
              "      <td>0.979344</td>\n",
              "      <td>0.956059</td>\n",
              "      <td>0.877925</td>\n",
              "      <td>1.188333</td>\n",
              "      <td>4.766695</td>\n",
              "      <td>4.841297</td>\n",
              "      <td>-0.074602</td>\n",
              "      <td>10.569099</td>\n",
              "      <td>0.958640</td>\n",
              "      <td>0.970049</td>\n",
              "      <td>0.948896</td>\n",
              "      <td>0.952042</td>\n",
              "      <td>0.932782</td>\n",
              "      <td>0.919646</td>\n",
              "      <td>0.870821</td>\n",
              "      <td>0.893630</td>\n",
              "      <td>0.818330</td>\n",
              "      <td>0.875869</td>\n",
              "      <td>0.858819</td>\n",
              "      <td>0.930045</td>\n",
              "      <td>1.207848</td>\n",
              "      <td>1.038071</td>\n",
              "      <td>-12.0</td>\n",
              "      <td>Information Technology</td>\n",
              "      <td>Technology Hardware, Storage &amp; Peripherals</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1993-11-17</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>1.019352</td>\n",
              "      <td>1.049333</td>\n",
              "      <td>0.981875</td>\n",
              "      <td>1.004361</td>\n",
              "      <td>75656000.0</td>\n",
              "      <td>28.403647</td>\n",
              "      <td>28.403647</td>\n",
              "      <td>28.157154</td>\n",
              "      <td>28.232998</td>\n",
              "      <td>39600</td>\n",
              "      <td>-0.005345</td>\n",
              "      <td>-0.014706</td>\n",
              "      <td>-0.009361</td>\n",
              "      <td>1993.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>321.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>66.377966</td>\n",
              "      <td>71.428536</td>\n",
              "      <td>151.958030</td>\n",
              "      <td>2.248565e-02</td>\n",
              "      <td>-2.998086e-02</td>\n",
              "      <td>0.022486</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>38.889732</td>\n",
              "      <td>34.763804</td>\n",
              "      <td>10.032138</td>\n",
              "      <td>0.112770</td>\n",
              "      <td>0.056214</td>\n",
              "      <td>0.044519</td>\n",
              "      <td>0.042942</td>\n",
              "      <td>0.581466</td>\n",
              "      <td>-28.571464</td>\n",
              "      <td>0.098018</td>\n",
              "      <td>0.030561</td>\n",
              "      <td>60.312542</td>\n",
              "      <td>0.967932</td>\n",
              "      <td>0.983253</td>\n",
              "      <td>0.963862</td>\n",
              "      <td>0.950021</td>\n",
              "      <td>0.904185</td>\n",
              "      <td>0.951894</td>\n",
              "      <td>0.937613</td>\n",
              "      <td>0.992828</td>\n",
              "      <td>0.996124</td>\n",
              "      <td>0.869401</td>\n",
              "      <td>0.598100</td>\n",
              "      <td>0.263158</td>\n",
              "      <td>0.933105</td>\n",
              "      <td>0.985639</td>\n",
              "      <td>0.967135</td>\n",
              "      <td>0.885831</td>\n",
              "      <td>1.187179</td>\n",
              "      <td>4.891057</td>\n",
              "      <td>4.851249</td>\n",
              "      <td>0.039808</td>\n",
              "      <td>6.349172</td>\n",
              "      <td>0.975130</td>\n",
              "      <td>0.981487</td>\n",
              "      <td>0.954518</td>\n",
              "      <td>0.961555</td>\n",
              "      <td>0.941401</td>\n",
              "      <td>0.927714</td>\n",
              "      <td>0.880690</td>\n",
              "      <td>0.900774</td>\n",
              "      <td>0.822377</td>\n",
              "      <td>0.880909</td>\n",
              "      <td>0.856885</td>\n",
              "      <td>0.931542</td>\n",
              "      <td>1.203953</td>\n",
              "      <td>1.037685</td>\n",
              "      <td>-12.0</td>\n",
              "      <td>Information Technology</td>\n",
              "      <td>Technology Hardware, Storage &amp; Peripherals</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           ticker  ...                                    industry\n",
              "date               ...                                            \n",
              "1993-11-11   AAPL  ...  Technology Hardware, Storage & Peripherals\n",
              "1993-11-12   AAPL  ...  Technology Hardware, Storage & Peripherals\n",
              "1993-11-15   AAPL  ...  Technology Hardware, Storage & Peripherals\n",
              "1993-11-16   AAPL  ...  Technology Hardware, Storage & Peripherals\n",
              "1993-11-17   AAPL  ...  Technology Hardware, Storage & Peripherals\n",
              "\n",
              "[5 rows x 77 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLC25MnEwaNh",
        "colab_type": "text"
      },
      "source": [
        "#### Define features and targets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzTeephGwg0N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define features and target\n",
        "X, y = data.drop('short_result', axis=1), data['short_result']\n",
        "train = data[data['year'] <= 2018]\n",
        "val = data[(data['year'] > 2018) & (data['year'] <= 2019)]\n",
        "test = data[data['year'] > 2019]\n",
        "\n",
        "X_train, y_train = train.drop('short_result', axis=1), train['short_result']\n",
        "X_test, y_test = test.drop('short_result', axis=1), test['short_result']\n",
        "X_val, y_val = val.drop('short_result', axis=1), val['short_result']\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A01fJMW1wqiV",
        "colab_type": "text"
      },
      "source": [
        "#### Build a Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y87xZZ5rt2iz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531
        },
        "outputId": "07a50911-1fe6-4473-853f-496654cbc971"
      },
      "source": [
        "#Pipeline\n",
        "#Column transformation\n",
        "# determine categorical and numerical features\n",
        "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_cols = X.select_dtypes(include=['object', 'bool']).columns\n",
        "\n",
        "# Column preparation\n",
        "transformer = [\n",
        "               ('scaler', MinMaxScaler(feature_range=(0,1)), numerical_cols),\n",
        "               ('onehot', OneHotEncoder(sparse=False), categorical_cols)]\n",
        "col_transform = ColumnTransformer(transformers=transformer)\n",
        "\n",
        "pipeline_x = Pipeline(steps=[('prep', col_transform),\n",
        "                             ('pca', PCA(n_components=60, random_state=1))])\n",
        "pipeline_y =  Pipeline(steps=[('scaler', MinMaxScaler(feature_range=(0,1)))])\n",
        "\n",
        "pipeline_x.fit(X)\n",
        "pipeline_y.fit(y.values.reshape(-1, 1))\n",
        "\n",
        "joblib.dump(pipeline_x, 'pipeline_x.pkl', compress=1)\n",
        "joblib.dump(pipeline_y, 'pipeline_y.pkl', compress=1)\n",
        "\n",
        "with open('pipeline_x.pkl',  'rb') as f_x:\n",
        "    pipeline_x_loaded = joblib.load(f_x)\n",
        "\n",
        "with open('pipeline_y.pkl',  'rb') as f_y:\n",
        "    pipeline_y_loaded = joblib.load(f_y)\n",
        "\n",
        "X_train_scaled, y_train_scaled = pipeline_x_loaded.transform(X_train), pipeline_y_loaded.transform(y_train.values.reshape((-1,1)))\n",
        "X_val_scaled, y_val_scaled = pipeline_x_loaded.transform(X_val), pipeline_y_loaded.transform(y_val.values.reshape((-1,1)))\n",
        "\n",
        "X_train_scaled.astype('float32')\n",
        "y_train_scaled.astype('float32')\n",
        "\n",
        "X_val_scaled.astype('float32')\n",
        "y_val_scaled.astype('float32')\n",
        "\n",
        "print('Min value: ', round(X_train_scaled.min(),2))\n",
        "print('Max value: ', round(X_train_scaled.max(),2))\n",
        "plt.hist(X_train_scaled);\n",
        "print(X_train_scaled.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Min value:  -1.45\n",
            "Max value:  1.67\n",
            "(266487, 60)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VM5y5O7t53ez",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "29845212-4cc8-447d-f535-7b4541267dc1"
      },
      "source": [
        "print('Min value: ', round(y_train_scaled.min(),2))\n",
        "print('Max value: ', round(y_train_scaled.max(),2))\n",
        "plt.hist(y_train_scaled, bins=200);"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Min value:  0.0\n",
            "Max value:  1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEvYggrGvDE9",
        "colab_type": "text"
      },
      "source": [
        "#### Split the data into sequences to be used for the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mi4owvIZt2mE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "006631e1-d1fa-4037-e437-de974edad81c"
      },
      "source": [
        "# Split into sequences\n",
        "def split_sequences(sequences, n_steps_split):\n",
        "    X, y = list(), list()\n",
        "    for i in range(len(sequences)):\n",
        "        # find the end of this pattern\n",
        "        end_ix = i + n_steps_split\n",
        "        # check if we are beyond the dataset\n",
        "        if end_ix > len(sequences):\n",
        "            break\n",
        "        # gather input and output parts of the pattern\n",
        "        seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix - 1, -1]\n",
        "        X.append(seq_x)\n",
        "        y.append(seq_y)\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "\n",
        "# choose a number of time steps\n",
        "n_steps_split = 20\n",
        "# Concat features and target\n",
        "train_dataset = np.hstack((X_train_scaled, y_train_scaled))\n",
        "val_dataset = np.hstack((X_val_scaled, y_val_scaled))\n",
        "# convert into input/output\n",
        "X_train_split, y_train_split = split_sequences(train_dataset, n_steps_split)\n",
        "y_train_split = np.reshape(y_train_split, (-1, 1))\n",
        "X_val_split, y_val_split = split_sequences(val_dataset, n_steps_split)\n",
        "y_val_split = np.reshape(y_val_split, (-1, 1))\n",
        "\n",
        "# the dataset knows the number of features, e.g. 2\n",
        "n_features = X_train_split.shape[2]\n",
        "n_seq = 4\n",
        "n_steps = 5\n",
        "#We can define the ConvLSTM as a single layer in terms of the number of filters\n",
        "#and a two-dimensional kernel size in terms of (rows, columns).\n",
        "#As we are working with a one-dimensional series, the number of rows is always\n",
        "#fixed to 1 in the kernel.\n",
        "rows = 1\n",
        "\n",
        "X_train_split = X_train_split.reshape((X_train_split.shape[0], n_seq, rows, n_steps, n_features))\n",
        "X_val_split = X_val_split.reshape((X_val_split.shape[0], n_seq, rows, n_steps, n_features))\n",
        "\n",
        "print(X_train_split.shape, y_train_split.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(266468, 4, 1, 5, 60) (266468, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ij6Qb1DQxuTk",
        "colab_type": "text"
      },
      "source": [
        "## Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41BHvls2xnaC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "143bb50f-8535-4c21-9b4e-0719f90430d9"
      },
      "source": [
        "# define model\n",
        "model = Sequential()\n",
        "model.add(ConvLSTM2D(filters=40, kernel_size=(4, 5), activation='relu', input_shape=(n_seq, rows, n_steps, n_features),\n",
        "                     padding='same', return_sequences=True, go_backwards=True, kernel_regularizer='l2', dropout=0.2))\n",
        "model.add(BatchNormalization())\n",
        "model.add(ConvLSTM2D(filters=40, kernel_size=(4, 5), activation='relu', input_shape=(n_seq, rows, n_steps, n_features),\n",
        "                     padding='same', return_sequences=True, go_backwards=True, kernel_regularizer='l2', dropout=0.2))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Flatten())\n",
        "model.add(RepeatVector(1))\n",
        "model.add(TimeDistributed(Dense(1)))\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "# Model path\n",
        "checkpoint_path = 'ConvLSTM2D_model.h5'\n",
        "\n",
        "## Callbacks:\n",
        "# Create a callback that saves the model's weights\n",
        "cp_callback = ModelCheckpoint(filepath=checkpoint_path,\n",
        "                              save_weights_only=False,\n",
        "                              verbose=1, save_best_only=True,\n",
        "                              monitor='loss')\n",
        "# Create a callback that prevents the overfitting\n",
        "early_stopping = EarlyStopping(monitor='loss', mode='auto', verbose=2,\n",
        "                               patience=10)\n",
        "# Create a callback to increase the learning rate\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
        "                              patience=1, min_lr=1e-5, mode='min')\n",
        "\n",
        "# fit model\n",
        "history = model.fit(X_train_split, y_train_split, epochs=100, batch_size=1024,\n",
        "                    callbacks=[cp_callback, early_stopping, reduce_lr],\n",
        "                    validation_data=(X_val_split, y_val_split), shuffle=True)\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "  2/261 [..............................] - ETA: 15s - loss: 2.8722 - mae: 0.9066WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0459s vs `on_train_batch_end` time: 0.0714s). Check your callbacks.\n",
            "261/261 [==============================] - ETA: 0s - loss: 0.2179 - mae: 0.1190\n",
            "Epoch 00001: loss improved from inf to 0.21785, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 117ms/step - loss: 0.2179 - mae: 0.1190 - val_loss: 0.1043 - val_mae: 0.2333\n",
            "Epoch 2/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 0.0349 - mae: 0.0419\n",
            "Epoch 00002: loss improved from 0.21785 to 0.03489, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 115ms/step - loss: 0.0349 - mae: 0.0419 - val_loss: 0.0243 - val_mae: 0.0662\n",
            "Epoch 3/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 0.0150 - mae: 0.0341\n",
            "Epoch 00003: loss improved from 0.03489 to 0.01505, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 115ms/step - loss: 0.0150 - mae: 0.0341 - val_loss: 0.0094 - val_mae: 0.0281\n",
            "Epoch 4/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 0.0072 - mae: 0.0309\n",
            "Epoch 00004: loss improved from 0.01505 to 0.00715, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 115ms/step - loss: 0.0072 - mae: 0.0309 - val_loss: 0.0052 - val_mae: 0.0351\n",
            "Epoch 5/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 0.0036 - mae: 0.0263\n",
            "Epoch 00005: loss improved from 0.00715 to 0.00359, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 0.0036 - mae: 0.0263 - val_loss: 0.0032 - val_mae: 0.0363\n",
            "Epoch 6/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 0.0020 - mae: 0.0227\n",
            "Epoch 00006: loss improved from 0.00359 to 0.00202, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 0.0020 - mae: 0.0227 - val_loss: 0.0020 - val_mae: 0.0323\n",
            "Epoch 7/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 0.0014 - mae: 0.0217\n",
            "Epoch 00007: loss improved from 0.00202 to 0.00141, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 115ms/step - loss: 0.0014 - mae: 0.0217 - val_loss: 7.7558e-04 - val_mae: 0.0178\n",
            "Epoch 8/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 0.0012 - mae: 0.0216\n",
            "Epoch 00008: loss improved from 0.00141 to 0.00118, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 0.0012 - mae: 0.0216 - val_loss: 5.4884e-04 - val_mae: 0.0160\n",
            "Epoch 9/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 0.0011 - mae: 0.0216\n",
            "Epoch 00009: loss improved from 0.00118 to 0.00109, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 115ms/step - loss: 0.0011 - mae: 0.0216 - val_loss: 4.7554e-04 - val_mae: 0.0158\n",
            "Epoch 10/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 0.0010 - mae: 0.0214\n",
            "Epoch 00010: loss improved from 0.00109 to 0.00105, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 0.0010 - mae: 0.0214 - val_loss: 4.6250e-04 - val_mae: 0.0157\n",
            "Epoch 11/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 0.0010 - mae: 0.0214\n",
            "Epoch 00011: loss improved from 0.00105 to 0.00104, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 115ms/step - loss: 0.0010 - mae: 0.0214 - val_loss: 4.6026e-04 - val_mae: 0.0157\n",
            "Epoch 12/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 0.0010 - mae: 0.0213\n",
            "Epoch 00012: loss improved from 0.00104 to 0.00104, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 115ms/step - loss: 0.0010 - mae: 0.0213 - val_loss: 4.6055e-04 - val_mae: 0.0157\n",
            "Epoch 13/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 0.0010 - mae: 0.0213\n",
            "Epoch 00013: loss improved from 0.00104 to 0.00103, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 115ms/step - loss: 0.0010 - mae: 0.0213 - val_loss: 4.6103e-04 - val_mae: 0.0157\n",
            "Epoch 14/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 0.0010 - mae: 0.0213\n",
            "Epoch 00014: loss improved from 0.00103 to 0.00103, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 115ms/step - loss: 0.0010 - mae: 0.0213 - val_loss: 4.6118e-04 - val_mae: 0.0157\n",
            "Epoch 15/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 0.0010 - mae: 0.0213\n",
            "Epoch 00015: loss improved from 0.00103 to 0.00103, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 0.0010 - mae: 0.0213 - val_loss: 4.6060e-04 - val_mae: 0.0157\n",
            "Epoch 16/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 0.0010 - mae: 0.0213\n",
            "Epoch 00016: loss improved from 0.00103 to 0.00103, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 0.0010 - mae: 0.0213 - val_loss: 4.6035e-04 - val_mae: 0.0157\n",
            "Epoch 17/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 0.0010 - mae: 0.0213\n",
            "Epoch 00017: loss improved from 0.00103 to 0.00103, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 0.0010 - mae: 0.0213 - val_loss: 4.5981e-04 - val_mae: 0.0157\n",
            "Epoch 18/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 0.0010 - mae: 0.0213\n",
            "Epoch 00018: loss improved from 0.00103 to 0.00103, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 115ms/step - loss: 0.0010 - mae: 0.0213 - val_loss: 4.6042e-04 - val_mae: 0.0157\n",
            "Epoch 19/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 0.0010 - mae: 0.0213\n",
            "Epoch 00019: loss improved from 0.00103 to 0.00103, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 115ms/step - loss: 0.0010 - mae: 0.0213 - val_loss: 4.6024e-04 - val_mae: 0.0157\n",
            "Epoch 20/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 0.0010 - mae: 0.0213\n",
            "Epoch 00020: loss improved from 0.00103 to 0.00103, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 0.0010 - mae: 0.0213 - val_loss: 4.6024e-04 - val_mae: 0.0157\n",
            "Epoch 21/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 0.0010 - mae: 0.0213\n",
            "Epoch 00021: loss improved from 0.00103 to 0.00103, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 115ms/step - loss: 0.0010 - mae: 0.0213 - val_loss: 4.5767e-04 - val_mae: 0.0157\n",
            "Epoch 22/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 0.0010 - mae: 0.0213\n",
            "Epoch 00022: loss improved from 0.00103 to 0.00103, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 115ms/step - loss: 0.0010 - mae: 0.0213 - val_loss: 4.5836e-04 - val_mae: 0.0157\n",
            "Epoch 23/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 0.0010 - mae: 0.0213\n",
            "Epoch 00023: loss improved from 0.00103 to 0.00103, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 115ms/step - loss: 0.0010 - mae: 0.0213 - val_loss: 4.5666e-04 - val_mae: 0.0157\n",
            "Epoch 24/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 0.0010 - mae: 0.0213\n",
            "Epoch 00024: loss improved from 0.00103 to 0.00102, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 0.0010 - mae: 0.0213 - val_loss: 4.5695e-04 - val_mae: 0.0157\n",
            "Epoch 25/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 0.0010 - mae: 0.0213\n",
            "Epoch 00025: loss improved from 0.00102 to 0.00102, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 0.0010 - mae: 0.0213 - val_loss: 4.5565e-04 - val_mae: 0.0158\n",
            "Epoch 26/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 0.0010 - mae: 0.0213\n",
            "Epoch 00026: loss improved from 0.00102 to 0.00102, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 115ms/step - loss: 0.0010 - mae: 0.0213 - val_loss: 4.5388e-04 - val_mae: 0.0157\n",
            "Epoch 27/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 0.0010 - mae: 0.0213\n",
            "Epoch 00027: loss improved from 0.00102 to 0.00102, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 0.0010 - mae: 0.0213 - val_loss: 4.5454e-04 - val_mae: 0.0157\n",
            "Epoch 28/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 0.0010 - mae: 0.0213\n",
            "Epoch 00028: loss improved from 0.00102 to 0.00102, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 0.0010 - mae: 0.0213 - val_loss: 4.5362e-04 - val_mae: 0.0158\n",
            "Epoch 29/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 0.0010 - mae: 0.0213\n",
            "Epoch 00029: loss improved from 0.00102 to 0.00102, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 115ms/step - loss: 0.0010 - mae: 0.0213 - val_loss: 4.5376e-04 - val_mae: 0.0157\n",
            "Epoch 30/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 0.0010 - mae: 0.0213\n",
            "Epoch 00030: loss improved from 0.00102 to 0.00102, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 0.0010 - mae: 0.0213 - val_loss: 4.5300e-04 - val_mae: 0.0157\n",
            "Epoch 31/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 0.0010 - mae: 0.0213\n",
            "Epoch 00031: loss improved from 0.00102 to 0.00101, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 115ms/step - loss: 0.0010 - mae: 0.0213 - val_loss: 4.4899e-04 - val_mae: 0.0157\n",
            "Epoch 32/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 0.0010 - mae: 0.0213\n",
            "Epoch 00032: loss improved from 0.00101 to 0.00101, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 0.0010 - mae: 0.0213 - val_loss: 4.4958e-04 - val_mae: 0.0158\n",
            "Epoch 33/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 0.0010 - mae: 0.0213\n",
            "Epoch 00033: loss improved from 0.00101 to 0.00101, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 115ms/step - loss: 0.0010 - mae: 0.0213 - val_loss: 4.4853e-04 - val_mae: 0.0157\n",
            "Epoch 34/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 0.0010 - mae: 0.0213\n",
            "Epoch 00034: loss improved from 0.00101 to 0.00101, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 115ms/step - loss: 0.0010 - mae: 0.0213 - val_loss: 4.4687e-04 - val_mae: 0.0158\n",
            "Epoch 35/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 0.0010 - mae: 0.0213\n",
            "Epoch 00035: loss improved from 0.00101 to 0.00101, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 0.0010 - mae: 0.0213 - val_loss: 4.5012e-04 - val_mae: 0.0158\n",
            "Epoch 36/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 0.0010 - mae: 0.0213\n",
            "Epoch 00036: loss improved from 0.00101 to 0.00101, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 0.0010 - mae: 0.0213 - val_loss: 4.4489e-04 - val_mae: 0.0158\n",
            "Epoch 37/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 0.0010 - mae: 0.0213\n",
            "Epoch 00037: loss improved from 0.00101 to 0.00101, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 115ms/step - loss: 0.0010 - mae: 0.0213 - val_loss: 4.4756e-04 - val_mae: 0.0159\n",
            "Epoch 38/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 0.0010 - mae: 0.0213\n",
            "Epoch 00038: loss improved from 0.00101 to 0.00101, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 115ms/step - loss: 0.0010 - mae: 0.0213 - val_loss: 4.4576e-04 - val_mae: 0.0158\n",
            "Epoch 39/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 0.0010 - mae: 0.0213\n",
            "Epoch 00039: loss did not improve from 0.00101\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 0.0010 - mae: 0.0213 - val_loss: 4.4535e-04 - val_mae: 0.0157\n",
            "Epoch 40/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 0.0010 - mae: 0.0213\n",
            "Epoch 00040: loss improved from 0.00101 to 0.00100, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 115ms/step - loss: 0.0010 - mae: 0.0213 - val_loss: 4.4615e-04 - val_mae: 0.0158\n",
            "Epoch 41/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 0.0010 - mae: 0.0213\n",
            "Epoch 00041: loss improved from 0.00100 to 0.00100, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 0.0010 - mae: 0.0213 - val_loss: 4.4464e-04 - val_mae: 0.0158\n",
            "Epoch 42/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 0.0010 - mae: 0.0213\n",
            "Epoch 00042: loss improved from 0.00100 to 0.00100, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 115ms/step - loss: 0.0010 - mae: 0.0213 - val_loss: 4.4727e-04 - val_mae: 0.0158\n",
            "Epoch 43/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 0.0010 - mae: 0.0213\n",
            "Epoch 00043: loss improved from 0.00100 to 0.00100, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 115ms/step - loss: 0.0010 - mae: 0.0213 - val_loss: 4.4975e-04 - val_mae: 0.0158\n",
            "Epoch 44/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 0.0010 - mae: 0.0213\n",
            "Epoch 00044: loss improved from 0.00100 to 0.00100, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 0.0010 - mae: 0.0213 - val_loss: 4.5029e-04 - val_mae: 0.0158\n",
            "Epoch 45/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 0.0010 - mae: 0.0213\n",
            "Epoch 00045: loss improved from 0.00100 to 0.00100, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 0.0010 - mae: 0.0213 - val_loss: 4.4459e-04 - val_mae: 0.0157\n",
            "Epoch 46/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 0.0010 - mae: 0.0213\n",
            "Epoch 00046: loss did not improve from 0.00100\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 0.0010 - mae: 0.0213 - val_loss: 4.4572e-04 - val_mae: 0.0158\n",
            "Epoch 47/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 0.0010 - mae: 0.0213\n",
            "Epoch 00047: loss did not improve from 0.00100\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 0.0010 - mae: 0.0213 - val_loss: 4.4629e-04 - val_mae: 0.0157\n",
            "Epoch 48/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 0.0010 - mae: 0.0213\n",
            "Epoch 00048: loss improved from 0.00100 to 0.00100, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 0.0010 - mae: 0.0213 - val_loss: 4.4935e-04 - val_mae: 0.0158\n",
            "Epoch 49/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 0.0010 - mae: 0.0213\n",
            "Epoch 00049: loss did not improve from 0.00100\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 0.0010 - mae: 0.0213 - val_loss: 4.4627e-04 - val_mae: 0.0158\n",
            "Epoch 50/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 0.0010 - mae: 0.0213\n",
            "Epoch 00050: loss improved from 0.00100 to 0.00100, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 0.0010 - mae: 0.0213 - val_loss: 4.5205e-04 - val_mae: 0.0158\n",
            "Epoch 51/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.9965e-04 - mae: 0.0212\n",
            "Epoch 00051: loss improved from 0.00100 to 0.00100, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.9965e-04 - mae: 0.0212 - val_loss: 4.5015e-04 - val_mae: 0.0158\n",
            "Epoch 52/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 0.0010 - mae: 0.0213    \n",
            "Epoch 00052: loss did not improve from 0.00100\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 0.0010 - mae: 0.0213 - val_loss: 4.4494e-04 - val_mae: 0.0157\n",
            "Epoch 53/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.9946e-04 - mae: 0.0212\n",
            "Epoch 00053: loss improved from 0.00100 to 0.00100, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 115ms/step - loss: 9.9946e-04 - mae: 0.0212 - val_loss: 4.5645e-04 - val_mae: 0.0158\n",
            "Epoch 54/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.9846e-04 - mae: 0.0212\n",
            "Epoch 00054: loss improved from 0.00100 to 0.00100, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 115ms/step - loss: 9.9846e-04 - mae: 0.0212 - val_loss: 4.5830e-04 - val_mae: 0.0159\n",
            "Epoch 55/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.9987e-04 - mae: 0.0212\n",
            "Epoch 00055: loss did not improve from 0.00100\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.9987e-04 - mae: 0.0212 - val_loss: 4.4972e-04 - val_mae: 0.0158\n",
            "Epoch 56/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.9882e-04 - mae: 0.0212\n",
            "Epoch 00056: loss did not improve from 0.00100\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.9882e-04 - mae: 0.0212 - val_loss: 4.5088e-04 - val_mae: 0.0158\n",
            "Epoch 57/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.9907e-04 - mae: 0.0212\n",
            "Epoch 00057: loss did not improve from 0.00100\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.9907e-04 - mae: 0.0212 - val_loss: 4.4856e-04 - val_mae: 0.0158\n",
            "Epoch 58/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.9837e-04 - mae: 0.0212\n",
            "Epoch 00058: loss improved from 0.00100 to 0.00100, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.9837e-04 - mae: 0.0212 - val_loss: 4.4564e-04 - val_mae: 0.0157\n",
            "Epoch 59/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.9806e-04 - mae: 0.0212\n",
            "Epoch 00059: loss improved from 0.00100 to 0.00100, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.9806e-04 - mae: 0.0212 - val_loss: 4.4878e-04 - val_mae: 0.0157\n",
            "Epoch 60/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.9799e-04 - mae: 0.0212\n",
            "Epoch 00060: loss improved from 0.00100 to 0.00100, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.9799e-04 - mae: 0.0212 - val_loss: 4.5205e-04 - val_mae: 0.0158\n",
            "Epoch 61/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.9744e-04 - mae: 0.0212\n",
            "Epoch 00061: loss improved from 0.00100 to 0.00100, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.9744e-04 - mae: 0.0212 - val_loss: 4.4719e-04 - val_mae: 0.0158\n",
            "Epoch 62/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.9687e-04 - mae: 0.0212\n",
            "Epoch 00062: loss improved from 0.00100 to 0.00100, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.9687e-04 - mae: 0.0212 - val_loss: 4.5452e-04 - val_mae: 0.0159\n",
            "Epoch 63/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.9684e-04 - mae: 0.0212\n",
            "Epoch 00063: loss improved from 0.00100 to 0.00100, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.9684e-04 - mae: 0.0212 - val_loss: 4.4859e-04 - val_mae: 0.0158\n",
            "Epoch 64/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.9612e-04 - mae: 0.0212\n",
            "Epoch 00064: loss improved from 0.00100 to 0.00100, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 115ms/step - loss: 9.9612e-04 - mae: 0.0212 - val_loss: 4.5964e-04 - val_mae: 0.0159\n",
            "Epoch 65/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.9637e-04 - mae: 0.0212\n",
            "Epoch 00065: loss did not improve from 0.00100\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.9637e-04 - mae: 0.0212 - val_loss: 4.4853e-04 - val_mae: 0.0159\n",
            "Epoch 66/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.9573e-04 - mae: 0.0212\n",
            "Epoch 00066: loss improved from 0.00100 to 0.00100, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.9573e-04 - mae: 0.0212 - val_loss: 4.5029e-04 - val_mae: 0.0157\n",
            "Epoch 67/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.9543e-04 - mae: 0.0212\n",
            "Epoch 00067: loss improved from 0.00100 to 0.00100, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.9543e-04 - mae: 0.0212 - val_loss: 4.5337e-04 - val_mae: 0.0159\n",
            "Epoch 68/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.9578e-04 - mae: 0.0212\n",
            "Epoch 00068: loss did not improve from 0.00100\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.9578e-04 - mae: 0.0212 - val_loss: 4.5284e-04 - val_mae: 0.0159\n",
            "Epoch 69/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.9407e-04 - mae: 0.0212\n",
            "Epoch 00069: loss improved from 0.00100 to 0.00099, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.9407e-04 - mae: 0.0212 - val_loss: 4.5847e-04 - val_mae: 0.0159\n",
            "Epoch 70/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.9489e-04 - mae: 0.0212\n",
            "Epoch 00070: loss did not improve from 0.00099\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.9489e-04 - mae: 0.0212 - val_loss: 4.5815e-04 - val_mae: 0.0159\n",
            "Epoch 71/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.9432e-04 - mae: 0.0212\n",
            "Epoch 00071: loss did not improve from 0.00099\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.9432e-04 - mae: 0.0212 - val_loss: 4.4819e-04 - val_mae: 0.0158\n",
            "Epoch 72/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.9369e-04 - mae: 0.0212\n",
            "Epoch 00072: loss improved from 0.00099 to 0.00099, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.9369e-04 - mae: 0.0212 - val_loss: 4.5801e-04 - val_mae: 0.0159\n",
            "Epoch 73/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.9334e-04 - mae: 0.0212\n",
            "Epoch 00073: loss improved from 0.00099 to 0.00099, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.9334e-04 - mae: 0.0212 - val_loss: 4.5224e-04 - val_mae: 0.0159\n",
            "Epoch 74/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.9366e-04 - mae: 0.0212\n",
            "Epoch 00074: loss did not improve from 0.00099\n",
            "261/261 [==============================] - 30s 115ms/step - loss: 9.9366e-04 - mae: 0.0212 - val_loss: 4.5861e-04 - val_mae: 0.0160\n",
            "Epoch 75/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.9358e-04 - mae: 0.0212\n",
            "Epoch 00075: loss did not improve from 0.00099\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.9358e-04 - mae: 0.0212 - val_loss: 4.5263e-04 - val_mae: 0.0159\n",
            "Epoch 76/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.9304e-04 - mae: 0.0212\n",
            "Epoch 00076: loss improved from 0.00099 to 0.00099, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.9304e-04 - mae: 0.0212 - val_loss: 4.5498e-04 - val_mae: 0.0159\n",
            "Epoch 77/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.9203e-04 - mae: 0.0212\n",
            "Epoch 00077: loss improved from 0.00099 to 0.00099, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.9203e-04 - mae: 0.0212 - val_loss: 4.6327e-04 - val_mae: 0.0160\n",
            "Epoch 78/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.9185e-04 - mae: 0.0212\n",
            "Epoch 00078: loss improved from 0.00099 to 0.00099, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.9185e-04 - mae: 0.0212 - val_loss: 4.6630e-04 - val_mae: 0.0160\n",
            "Epoch 79/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.9216e-04 - mae: 0.0212\n",
            "Epoch 00079: loss did not improve from 0.00099\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.9216e-04 - mae: 0.0212 - val_loss: 4.5435e-04 - val_mae: 0.0160\n",
            "Epoch 80/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.9113e-04 - mae: 0.0212\n",
            "Epoch 00080: loss improved from 0.00099 to 0.00099, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.9113e-04 - mae: 0.0212 - val_loss: 4.5572e-04 - val_mae: 0.0160\n",
            "Epoch 81/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.9157e-04 - mae: 0.0212\n",
            "Epoch 00081: loss did not improve from 0.00099\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.9157e-04 - mae: 0.0212 - val_loss: 4.5197e-04 - val_mae: 0.0159\n",
            "Epoch 82/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.9158e-04 - mae: 0.0212\n",
            "Epoch 00082: loss did not improve from 0.00099\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.9158e-04 - mae: 0.0212 - val_loss: 4.5495e-04 - val_mae: 0.0158\n",
            "Epoch 83/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.9056e-04 - mae: 0.0212\n",
            "Epoch 00083: loss improved from 0.00099 to 0.00099, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.9056e-04 - mae: 0.0212 - val_loss: 4.5591e-04 - val_mae: 0.0160\n",
            "Epoch 84/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.9057e-04 - mae: 0.0212\n",
            "Epoch 00084: loss did not improve from 0.00099\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.9057e-04 - mae: 0.0212 - val_loss: 4.5835e-04 - val_mae: 0.0160\n",
            "Epoch 85/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.9002e-04 - mae: 0.0212\n",
            "Epoch 00085: loss improved from 0.00099 to 0.00099, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.9002e-04 - mae: 0.0212 - val_loss: 4.5429e-04 - val_mae: 0.0160\n",
            "Epoch 86/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.8959e-04 - mae: 0.0212\n",
            "Epoch 00086: loss improved from 0.00099 to 0.00099, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.8959e-04 - mae: 0.0212 - val_loss: 4.5170e-04 - val_mae: 0.0159\n",
            "Epoch 87/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.8899e-04 - mae: 0.0212\n",
            "Epoch 00087: loss improved from 0.00099 to 0.00099, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.8899e-04 - mae: 0.0212 - val_loss: 4.5521e-04 - val_mae: 0.0160\n",
            "Epoch 88/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.8857e-04 - mae: 0.0212\n",
            "Epoch 00088: loss improved from 0.00099 to 0.00099, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.8857e-04 - mae: 0.0212 - val_loss: 4.5714e-04 - val_mae: 0.0160\n",
            "Epoch 89/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.8850e-04 - mae: 0.0212\n",
            "Epoch 00089: loss improved from 0.00099 to 0.00099, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.8850e-04 - mae: 0.0212 - val_loss: 4.5861e-04 - val_mae: 0.0160\n",
            "Epoch 90/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.8928e-04 - mae: 0.0212\n",
            "Epoch 00090: loss did not improve from 0.00099\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.8928e-04 - mae: 0.0212 - val_loss: 4.7209e-04 - val_mae: 0.0162\n",
            "Epoch 91/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.8809e-04 - mae: 0.0212\n",
            "Epoch 00091: loss improved from 0.00099 to 0.00099, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.8809e-04 - mae: 0.0212 - val_loss: 4.6178e-04 - val_mae: 0.0159\n",
            "Epoch 92/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.8827e-04 - mae: 0.0212\n",
            "Epoch 00092: loss did not improve from 0.00099\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.8827e-04 - mae: 0.0212 - val_loss: 4.5659e-04 - val_mae: 0.0161\n",
            "Epoch 93/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.8715e-04 - mae: 0.0212\n",
            "Epoch 00093: loss improved from 0.00099 to 0.00099, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.8715e-04 - mae: 0.0212 - val_loss: 4.5960e-04 - val_mae: 0.0160\n",
            "Epoch 94/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.8769e-04 - mae: 0.0212\n",
            "Epoch 00094: loss did not improve from 0.00099\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.8769e-04 - mae: 0.0212 - val_loss: 4.6167e-04 - val_mae: 0.0160\n",
            "Epoch 95/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.8724e-04 - mae: 0.0212\n",
            "Epoch 00095: loss did not improve from 0.00099\n",
            "261/261 [==============================] - 30s 115ms/step - loss: 9.8724e-04 - mae: 0.0212 - val_loss: 4.6433e-04 - val_mae: 0.0161\n",
            "Epoch 96/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.8734e-04 - mae: 0.0212\n",
            "Epoch 00096: loss did not improve from 0.00099\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.8734e-04 - mae: 0.0212 - val_loss: 4.6101e-04 - val_mae: 0.0160\n",
            "Epoch 97/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.8796e-04 - mae: 0.0212\n",
            "Epoch 00097: loss did not improve from 0.00099\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.8796e-04 - mae: 0.0212 - val_loss: 4.5908e-04 - val_mae: 0.0161\n",
            "Epoch 98/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.8663e-04 - mae: 0.0212\n",
            "Epoch 00098: loss improved from 0.00099 to 0.00099, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.8663e-04 - mae: 0.0212 - val_loss: 4.6305e-04 - val_mae: 0.0160\n",
            "Epoch 99/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.8526e-04 - mae: 0.0212\n",
            "Epoch 00099: loss improved from 0.00099 to 0.00099, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.8526e-04 - mae: 0.0212 - val_loss: 4.6233e-04 - val_mae: 0.0160\n",
            "Epoch 100/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.8516e-04 - mae: 0.0212\n",
            "Epoch 00100: loss improved from 0.00099 to 0.00099, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.8516e-04 - mae: 0.0212 - val_loss: 4.7815e-04 - val_mae: 0.0163\n",
            "Epoch 101/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.8527e-04 - mae: 0.0212\n",
            "Epoch 00101: loss did not improve from 0.00099\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.8527e-04 - mae: 0.0212 - val_loss: 4.6336e-04 - val_mae: 0.0161\n",
            "Epoch 102/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.8602e-04 - mae: 0.0212\n",
            "Epoch 00102: loss did not improve from 0.00099\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.8602e-04 - mae: 0.0212 - val_loss: 4.6296e-04 - val_mae: 0.0161\n",
            "Epoch 103/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.8447e-04 - mae: 0.0212\n",
            "Epoch 00103: loss improved from 0.00099 to 0.00098, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.8447e-04 - mae: 0.0212 - val_loss: 4.7093e-04 - val_mae: 0.0162\n",
            "Epoch 104/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.8428e-04 - mae: 0.0212\n",
            "Epoch 00104: loss improved from 0.00098 to 0.00098, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 115ms/step - loss: 9.8428e-04 - mae: 0.0212 - val_loss: 4.6791e-04 - val_mae: 0.0162\n",
            "Epoch 105/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.8395e-04 - mae: 0.0212\n",
            "Epoch 00105: loss improved from 0.00098 to 0.00098, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.8395e-04 - mae: 0.0212 - val_loss: 4.7233e-04 - val_mae: 0.0162\n",
            "Epoch 106/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.8497e-04 - mae: 0.0212\n",
            "Epoch 00106: loss did not improve from 0.00098\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.8497e-04 - mae: 0.0212 - val_loss: 4.6805e-04 - val_mae: 0.0162\n",
            "Epoch 107/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.8330e-04 - mae: 0.0211\n",
            "Epoch 00107: loss improved from 0.00098 to 0.00098, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.8330e-04 - mae: 0.0211 - val_loss: 4.7314e-04 - val_mae: 0.0163\n",
            "Epoch 108/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.8353e-04 - mae: 0.0211\n",
            "Epoch 00108: loss did not improve from 0.00098\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.8353e-04 - mae: 0.0211 - val_loss: 4.6755e-04 - val_mae: 0.0162\n",
            "Epoch 109/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.8284e-04 - mae: 0.0211\n",
            "Epoch 00109: loss improved from 0.00098 to 0.00098, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.8284e-04 - mae: 0.0211 - val_loss: 4.6513e-04 - val_mae: 0.0162\n",
            "Epoch 110/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.8342e-04 - mae: 0.0211\n",
            "Epoch 00110: loss did not improve from 0.00098\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.8342e-04 - mae: 0.0211 - val_loss: 4.6699e-04 - val_mae: 0.0163\n",
            "Epoch 111/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.8382e-04 - mae: 0.0212\n",
            "Epoch 00111: loss did not improve from 0.00098\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.8382e-04 - mae: 0.0212 - val_loss: 4.6528e-04 - val_mae: 0.0161\n",
            "Epoch 112/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.8287e-04 - mae: 0.0211\n",
            "Epoch 00112: loss did not improve from 0.00098\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.8287e-04 - mae: 0.0211 - val_loss: 4.6377e-04 - val_mae: 0.0162\n",
            "Epoch 113/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.8232e-04 - mae: 0.0211\n",
            "Epoch 00113: loss improved from 0.00098 to 0.00098, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.8232e-04 - mae: 0.0211 - val_loss: 4.6919e-04 - val_mae: 0.0162\n",
            "Epoch 114/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.8306e-04 - mae: 0.0211\n",
            "Epoch 00114: loss did not improve from 0.00098\n",
            "261/261 [==============================] - 30s 113ms/step - loss: 9.8306e-04 - mae: 0.0211 - val_loss: 4.7046e-04 - val_mae: 0.0163\n",
            "Epoch 115/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.8241e-04 - mae: 0.0211\n",
            "Epoch 00115: loss did not improve from 0.00098\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.8241e-04 - mae: 0.0211 - val_loss: 4.7230e-04 - val_mae: 0.0165\n",
            "Epoch 116/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.8168e-04 - mae: 0.0211\n",
            "Epoch 00116: loss improved from 0.00098 to 0.00098, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.8168e-04 - mae: 0.0211 - val_loss: 4.6849e-04 - val_mae: 0.0163\n",
            "Epoch 117/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.8143e-04 - mae: 0.0211\n",
            "Epoch 00117: loss improved from 0.00098 to 0.00098, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.8143e-04 - mae: 0.0211 - val_loss: 4.6476e-04 - val_mae: 0.0162\n",
            "Epoch 118/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.8149e-04 - mae: 0.0211\n",
            "Epoch 00118: loss did not improve from 0.00098\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.8149e-04 - mae: 0.0211 - val_loss: 4.7349e-04 - val_mae: 0.0163\n",
            "Epoch 119/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.8181e-04 - mae: 0.0211\n",
            "Epoch 00119: loss did not improve from 0.00098\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.8181e-04 - mae: 0.0211 - val_loss: 4.7043e-04 - val_mae: 0.0162\n",
            "Epoch 120/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.8244e-04 - mae: 0.0211\n",
            "Epoch 00120: loss did not improve from 0.00098\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.8244e-04 - mae: 0.0211 - val_loss: 4.7632e-04 - val_mae: 0.0164\n",
            "Epoch 121/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.8051e-04 - mae: 0.0211\n",
            "Epoch 00121: loss improved from 0.00098 to 0.00098, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.8051e-04 - mae: 0.0211 - val_loss: 4.8983e-04 - val_mae: 0.0166\n",
            "Epoch 122/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.8071e-04 - mae: 0.0211\n",
            "Epoch 00122: loss did not improve from 0.00098\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.8071e-04 - mae: 0.0211 - val_loss: 4.7273e-04 - val_mae: 0.0164\n",
            "Epoch 123/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.8080e-04 - mae: 0.0211\n",
            "Epoch 00123: loss did not improve from 0.00098\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.8080e-04 - mae: 0.0211 - val_loss: 4.6787e-04 - val_mae: 0.0163\n",
            "Epoch 124/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.7961e-04 - mae: 0.0211\n",
            "Epoch 00124: loss improved from 0.00098 to 0.00098, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.7961e-04 - mae: 0.0211 - val_loss: 4.7223e-04 - val_mae: 0.0164\n",
            "Epoch 125/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.7862e-04 - mae: 0.0211\n",
            "Epoch 00125: loss improved from 0.00098 to 0.00098, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.7862e-04 - mae: 0.0211 - val_loss: 4.8170e-04 - val_mae: 0.0164\n",
            "Epoch 126/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.8021e-04 - mae: 0.0211\n",
            "Epoch 00126: loss did not improve from 0.00098\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.8021e-04 - mae: 0.0211 - val_loss: 4.7781e-04 - val_mae: 0.0164\n",
            "Epoch 127/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.7984e-04 - mae: 0.0211\n",
            "Epoch 00127: loss did not improve from 0.00098\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.7984e-04 - mae: 0.0211 - val_loss: 4.7018e-04 - val_mae: 0.0163\n",
            "Epoch 128/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.7952e-04 - mae: 0.0211\n",
            "Epoch 00128: loss did not improve from 0.00098\n",
            "261/261 [==============================] - 30s 115ms/step - loss: 9.7952e-04 - mae: 0.0211 - val_loss: 4.7614e-04 - val_mae: 0.0164\n",
            "Epoch 129/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.7913e-04 - mae: 0.0211\n",
            "Epoch 00129: loss did not improve from 0.00098\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.7913e-04 - mae: 0.0211 - val_loss: 4.8199e-04 - val_mae: 0.0165\n",
            "Epoch 130/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.7938e-04 - mae: 0.0211\n",
            "Epoch 00130: loss did not improve from 0.00098\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.7938e-04 - mae: 0.0211 - val_loss: 4.6900e-04 - val_mae: 0.0162\n",
            "Epoch 131/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.8004e-04 - mae: 0.0211\n",
            "Epoch 00131: loss did not improve from 0.00098\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.8004e-04 - mae: 0.0211 - val_loss: 4.7171e-04 - val_mae: 0.0163\n",
            "Epoch 132/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.7892e-04 - mae: 0.0211\n",
            "Epoch 00132: loss did not improve from 0.00098\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.7892e-04 - mae: 0.0211 - val_loss: 4.8375e-04 - val_mae: 0.0165\n",
            "Epoch 133/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.7832e-04 - mae: 0.0211\n",
            "Epoch 00133: loss improved from 0.00098 to 0.00098, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.7832e-04 - mae: 0.0211 - val_loss: 4.7741e-04 - val_mae: 0.0164\n",
            "Epoch 134/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.7775e-04 - mae: 0.0211\n",
            "Epoch 00134: loss improved from 0.00098 to 0.00098, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.7775e-04 - mae: 0.0211 - val_loss: 4.8303e-04 - val_mae: 0.0165\n",
            "Epoch 135/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.7820e-04 - mae: 0.0211\n",
            "Epoch 00135: loss did not improve from 0.00098\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.7820e-04 - mae: 0.0211 - val_loss: 4.7449e-04 - val_mae: 0.0164\n",
            "Epoch 136/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.7853e-04 - mae: 0.0211\n",
            "Epoch 00136: loss did not improve from 0.00098\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.7853e-04 - mae: 0.0211 - val_loss: 4.7670e-04 - val_mae: 0.0164\n",
            "Epoch 137/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.7881e-04 - mae: 0.0211\n",
            "Epoch 00137: loss did not improve from 0.00098\n",
            "261/261 [==============================] - 30s 115ms/step - loss: 9.7881e-04 - mae: 0.0211 - val_loss: 4.7793e-04 - val_mae: 0.0164\n",
            "Epoch 138/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.7832e-04 - mae: 0.0211\n",
            "Epoch 00138: loss did not improve from 0.00098\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.7832e-04 - mae: 0.0211 - val_loss: 4.7242e-04 - val_mae: 0.0163\n",
            "Epoch 139/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.7800e-04 - mae: 0.0211\n",
            "Epoch 00139: loss did not improve from 0.00098\n",
            "261/261 [==============================] - 30s 113ms/step - loss: 9.7800e-04 - mae: 0.0211 - val_loss: 4.7906e-04 - val_mae: 0.0164\n",
            "Epoch 140/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.7765e-04 - mae: 0.0211\n",
            "Epoch 00140: loss improved from 0.00098 to 0.00098, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.7765e-04 - mae: 0.0211 - val_loss: 4.7289e-04 - val_mae: 0.0164\n",
            "Epoch 141/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.7694e-04 - mae: 0.0211\n",
            "Epoch 00141: loss improved from 0.00098 to 0.00098, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.7694e-04 - mae: 0.0211 - val_loss: 4.7327e-04 - val_mae: 0.0163\n",
            "Epoch 142/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.7714e-04 - mae: 0.0211\n",
            "Epoch 00142: loss did not improve from 0.00098\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.7714e-04 - mae: 0.0211 - val_loss: 4.8381e-04 - val_mae: 0.0165\n",
            "Epoch 143/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.7737e-04 - mae: 0.0211\n",
            "Epoch 00143: loss did not improve from 0.00098\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.7737e-04 - mae: 0.0211 - val_loss: 4.7039e-04 - val_mae: 0.0163\n",
            "Epoch 144/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.7772e-04 - mae: 0.0211\n",
            "Epoch 00144: loss did not improve from 0.00098\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.7772e-04 - mae: 0.0211 - val_loss: 4.7697e-04 - val_mae: 0.0165\n",
            "Epoch 145/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.7752e-04 - mae: 0.0211\n",
            "Epoch 00145: loss did not improve from 0.00098\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.7752e-04 - mae: 0.0211 - val_loss: 4.8272e-04 - val_mae: 0.0165\n",
            "Epoch 146/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.7620e-04 - mae: 0.0211\n",
            "Epoch 00146: loss improved from 0.00098 to 0.00098, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.7620e-04 - mae: 0.0211 - val_loss: 4.7450e-04 - val_mae: 0.0165\n",
            "Epoch 147/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.7602e-04 - mae: 0.0211\n",
            "Epoch 00147: loss improved from 0.00098 to 0.00098, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 115ms/step - loss: 9.7602e-04 - mae: 0.0211 - val_loss: 4.8242e-04 - val_mae: 0.0164\n",
            "Epoch 148/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.7590e-04 - mae: 0.0211\n",
            "Epoch 00148: loss improved from 0.00098 to 0.00098, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.7590e-04 - mae: 0.0211 - val_loss: 4.7260e-04 - val_mae: 0.0164\n",
            "Epoch 149/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.7628e-04 - mae: 0.0211\n",
            "Epoch 00149: loss did not improve from 0.00098\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.7628e-04 - mae: 0.0211 - val_loss: 4.7791e-04 - val_mae: 0.0164\n",
            "Epoch 150/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.7495e-04 - mae: 0.0211\n",
            "Epoch 00150: loss improved from 0.00098 to 0.00097, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.7495e-04 - mae: 0.0211 - val_loss: 4.7762e-04 - val_mae: 0.0164\n",
            "Epoch 151/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.7592e-04 - mae: 0.0211\n",
            "Epoch 00151: loss did not improve from 0.00097\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.7592e-04 - mae: 0.0211 - val_loss: 4.7347e-04 - val_mae: 0.0163\n",
            "Epoch 152/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.7569e-04 - mae: 0.0211\n",
            "Epoch 00152: loss did not improve from 0.00097\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.7569e-04 - mae: 0.0211 - val_loss: 4.7991e-04 - val_mae: 0.0164\n",
            "Epoch 153/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.7598e-04 - mae: 0.0211\n",
            "Epoch 00153: loss did not improve from 0.00097\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.7598e-04 - mae: 0.0211 - val_loss: 4.9413e-04 - val_mae: 0.0166\n",
            "Epoch 154/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.7400e-04 - mae: 0.0211\n",
            "Epoch 00154: loss improved from 0.00097 to 0.00097, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.7400e-04 - mae: 0.0211 - val_loss: 4.7410e-04 - val_mae: 0.0164\n",
            "Epoch 155/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.7516e-04 - mae: 0.0211\n",
            "Epoch 00155: loss did not improve from 0.00097\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.7516e-04 - mae: 0.0211 - val_loss: 4.9108e-04 - val_mae: 0.0166\n",
            "Epoch 156/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.7495e-04 - mae: 0.0211\n",
            "Epoch 00156: loss did not improve from 0.00097\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.7495e-04 - mae: 0.0211 - val_loss: 4.7924e-04 - val_mae: 0.0164\n",
            "Epoch 157/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.7391e-04 - mae: 0.0211\n",
            "Epoch 00157: loss improved from 0.00097 to 0.00097, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.7391e-04 - mae: 0.0211 - val_loss: 4.8814e-04 - val_mae: 0.0166\n",
            "Epoch 158/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.7465e-04 - mae: 0.0211\n",
            "Epoch 00158: loss did not improve from 0.00097\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.7465e-04 - mae: 0.0211 - val_loss: 4.7702e-04 - val_mae: 0.0163\n",
            "Epoch 159/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.7341e-04 - mae: 0.0211\n",
            "Epoch 00159: loss improved from 0.00097 to 0.00097, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.7341e-04 - mae: 0.0211 - val_loss: 4.7482e-04 - val_mae: 0.0163\n",
            "Epoch 160/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.7460e-04 - mae: 0.0211\n",
            "Epoch 00160: loss did not improve from 0.00097\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.7460e-04 - mae: 0.0211 - val_loss: 4.9421e-04 - val_mae: 0.0166\n",
            "Epoch 161/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.7424e-04 - mae: 0.0211\n",
            "Epoch 00161: loss did not improve from 0.00097\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.7424e-04 - mae: 0.0211 - val_loss: 4.7345e-04 - val_mae: 0.0164\n",
            "Epoch 162/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.7340e-04 - mae: 0.0211\n",
            "Epoch 00162: loss improved from 0.00097 to 0.00097, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.7340e-04 - mae: 0.0211 - val_loss: 4.8595e-04 - val_mae: 0.0165\n",
            "Epoch 163/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.7382e-04 - mae: 0.0211\n",
            "Epoch 00163: loss did not improve from 0.00097\n",
            "261/261 [==============================] - 30s 113ms/step - loss: 9.7382e-04 - mae: 0.0211 - val_loss: 4.6806e-04 - val_mae: 0.0162\n",
            "Epoch 164/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.7296e-04 - mae: 0.0211\n",
            "Epoch 00164: loss improved from 0.00097 to 0.00097, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.7296e-04 - mae: 0.0211 - val_loss: 4.9074e-04 - val_mae: 0.0165\n",
            "Epoch 165/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.7353e-04 - mae: 0.0211\n",
            "Epoch 00165: loss did not improve from 0.00097\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.7353e-04 - mae: 0.0211 - val_loss: 4.7800e-04 - val_mae: 0.0163\n",
            "Epoch 166/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.7348e-04 - mae: 0.0211\n",
            "Epoch 00166: loss did not improve from 0.00097\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.7348e-04 - mae: 0.0211 - val_loss: 4.8403e-04 - val_mae: 0.0165\n",
            "Epoch 167/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.7335e-04 - mae: 0.0211\n",
            "Epoch 00167: loss did not improve from 0.00097\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.7335e-04 - mae: 0.0211 - val_loss: 4.7625e-04 - val_mae: 0.0163\n",
            "Epoch 168/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.7287e-04 - mae: 0.0211\n",
            "Epoch 00168: loss improved from 0.00097 to 0.00097, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 115ms/step - loss: 9.7287e-04 - mae: 0.0211 - val_loss: 4.7983e-04 - val_mae: 0.0165\n",
            "Epoch 169/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.7190e-04 - mae: 0.0211\n",
            "Epoch 00169: loss improved from 0.00097 to 0.00097, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.7190e-04 - mae: 0.0211 - val_loss: 4.8131e-04 - val_mae: 0.0165\n",
            "Epoch 170/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.7360e-04 - mae: 0.0211\n",
            "Epoch 00170: loss did not improve from 0.00097\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.7360e-04 - mae: 0.0211 - val_loss: 4.9608e-04 - val_mae: 0.0166\n",
            "Epoch 171/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.7139e-04 - mae: 0.0211\n",
            "Epoch 00171: loss improved from 0.00097 to 0.00097, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.7139e-04 - mae: 0.0211 - val_loss: 5.0725e-04 - val_mae: 0.0169\n",
            "Epoch 172/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.7259e-04 - mae: 0.0211\n",
            "Epoch 00172: loss did not improve from 0.00097\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.7259e-04 - mae: 0.0211 - val_loss: 4.7706e-04 - val_mae: 0.0165\n",
            "Epoch 173/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.7246e-04 - mae: 0.0211\n",
            "Epoch 00173: loss did not improve from 0.00097\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.7246e-04 - mae: 0.0211 - val_loss: 4.8389e-04 - val_mae: 0.0165\n",
            "Epoch 174/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.7153e-04 - mae: 0.0211\n",
            "Epoch 00174: loss did not improve from 0.00097\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.7153e-04 - mae: 0.0211 - val_loss: 4.7966e-04 - val_mae: 0.0164\n",
            "Epoch 175/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.7166e-04 - mae: 0.0211\n",
            "Epoch 00175: loss did not improve from 0.00097\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.7166e-04 - mae: 0.0211 - val_loss: 4.8986e-04 - val_mae: 0.0165\n",
            "Epoch 176/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.7126e-04 - mae: 0.0210\n",
            "Epoch 00176: loss improved from 0.00097 to 0.00097, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.7126e-04 - mae: 0.0210 - val_loss: 4.8740e-04 - val_mae: 0.0165\n",
            "Epoch 177/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.7165e-04 - mae: 0.0211\n",
            "Epoch 00177: loss did not improve from 0.00097\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.7165e-04 - mae: 0.0211 - val_loss: 4.7659e-04 - val_mae: 0.0165\n",
            "Epoch 178/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.7264e-04 - mae: 0.0211\n",
            "Epoch 00178: loss did not improve from 0.00097\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.7264e-04 - mae: 0.0211 - val_loss: 4.8334e-04 - val_mae: 0.0164\n",
            "Epoch 179/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.7275e-04 - mae: 0.0211\n",
            "Epoch 00179: loss did not improve from 0.00097\n",
            "261/261 [==============================] - 30s 113ms/step - loss: 9.7275e-04 - mae: 0.0211 - val_loss: 4.7946e-04 - val_mae: 0.0163\n",
            "Epoch 180/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.7058e-04 - mae: 0.0210\n",
            "Epoch 00180: loss improved from 0.00097 to 0.00097, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.7058e-04 - mae: 0.0210 - val_loss: 4.8642e-04 - val_mae: 0.0165\n",
            "Epoch 181/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.7192e-04 - mae: 0.0211\n",
            "Epoch 00181: loss did not improve from 0.00097\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.7192e-04 - mae: 0.0211 - val_loss: 4.7299e-04 - val_mae: 0.0163\n",
            "Epoch 182/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.7115e-04 - mae: 0.0211\n",
            "Epoch 00182: loss did not improve from 0.00097\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.7115e-04 - mae: 0.0211 - val_loss: 4.8289e-04 - val_mae: 0.0165\n",
            "Epoch 183/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.7049e-04 - mae: 0.0210\n",
            "Epoch 00183: loss improved from 0.00097 to 0.00097, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.7049e-04 - mae: 0.0210 - val_loss: 4.9940e-04 - val_mae: 0.0167\n",
            "Epoch 184/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.7107e-04 - mae: 0.0210\n",
            "Epoch 00184: loss did not improve from 0.00097\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.7107e-04 - mae: 0.0210 - val_loss: 4.8174e-04 - val_mae: 0.0165\n",
            "Epoch 185/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.6983e-04 - mae: 0.0210\n",
            "Epoch 00185: loss improved from 0.00097 to 0.00097, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.6983e-04 - mae: 0.0210 - val_loss: 4.8962e-04 - val_mae: 0.0166\n",
            "Epoch 186/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.6987e-04 - mae: 0.0210\n",
            "Epoch 00186: loss did not improve from 0.00097\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.6987e-04 - mae: 0.0210 - val_loss: 4.8640e-04 - val_mae: 0.0165\n",
            "Epoch 187/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.6928e-04 - mae: 0.0210\n",
            "Epoch 00187: loss improved from 0.00097 to 0.00097, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.6928e-04 - mae: 0.0210 - val_loss: 4.8681e-04 - val_mae: 0.0165\n",
            "Epoch 188/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.6985e-04 - mae: 0.0210\n",
            "Epoch 00188: loss did not improve from 0.00097\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.6985e-04 - mae: 0.0210 - val_loss: 4.9604e-04 - val_mae: 0.0166\n",
            "Epoch 189/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.6969e-04 - mae: 0.0210\n",
            "Epoch 00189: loss did not improve from 0.00097\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.6969e-04 - mae: 0.0210 - val_loss: 4.9827e-04 - val_mae: 0.0167\n",
            "Epoch 190/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.6808e-04 - mae: 0.0210\n",
            "Epoch 00190: loss improved from 0.00097 to 0.00097, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.6808e-04 - mae: 0.0210 - val_loss: 4.9933e-04 - val_mae: 0.0168\n",
            "Epoch 191/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.6799e-04 - mae: 0.0210\n",
            "Epoch 00191: loss improved from 0.00097 to 0.00097, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.6799e-04 - mae: 0.0210 - val_loss: 4.7200e-04 - val_mae: 0.0164\n",
            "Epoch 192/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.6774e-04 - mae: 0.0210\n",
            "Epoch 00192: loss improved from 0.00097 to 0.00097, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.6774e-04 - mae: 0.0210 - val_loss: 4.7971e-04 - val_mae: 0.0165\n",
            "Epoch 193/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.6904e-04 - mae: 0.0210\n",
            "Epoch 00193: loss did not improve from 0.00097\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.6904e-04 - mae: 0.0210 - val_loss: 4.9131e-04 - val_mae: 0.0166\n",
            "Epoch 194/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.6816e-04 - mae: 0.0210\n",
            "Epoch 00194: loss did not improve from 0.00097\n",
            "261/261 [==============================] - 30s 113ms/step - loss: 9.6816e-04 - mae: 0.0210 - val_loss: 4.7697e-04 - val_mae: 0.0165\n",
            "Epoch 195/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.6831e-04 - mae: 0.0210\n",
            "Epoch 00195: loss did not improve from 0.00097\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.6831e-04 - mae: 0.0210 - val_loss: 4.8719e-04 - val_mae: 0.0165\n",
            "Epoch 196/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.6837e-04 - mae: 0.0210\n",
            "Epoch 00196: loss did not improve from 0.00097\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.6837e-04 - mae: 0.0210 - val_loss: 4.9763e-04 - val_mae: 0.0167\n",
            "Epoch 197/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.6737e-04 - mae: 0.0210\n",
            "Epoch 00197: loss improved from 0.00097 to 0.00097, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.6737e-04 - mae: 0.0210 - val_loss: 4.8198e-04 - val_mae: 0.0165\n",
            "Epoch 198/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.6862e-04 - mae: 0.0210\n",
            "Epoch 00198: loss did not improve from 0.00097\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.6862e-04 - mae: 0.0210 - val_loss: 4.9174e-04 - val_mae: 0.0167\n",
            "Epoch 199/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.6709e-04 - mae: 0.0210\n",
            "Epoch 00199: loss improved from 0.00097 to 0.00097, saving model to ConvLSTM2D_model.h5\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.6709e-04 - mae: 0.0210 - val_loss: 4.9641e-04 - val_mae: 0.0167\n",
            "Epoch 200/200\n",
            "261/261 [==============================] - ETA: 0s - loss: 9.6821e-04 - mae: 0.0210\n",
            "Epoch 00200: loss did not improve from 0.00097\n",
            "261/261 [==============================] - 30s 114ms/step - loss: 9.6821e-04 - mae: 0.0210 - val_loss: 4.9655e-04 - val_mae: 0.0167\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f419ef85a20>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xh5SHsZ83dtz",
        "colab_type": "text"
      },
      "source": [
        "## Test the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYfsO-N6wy57",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "f2608e77-1bb5-40e7-ae85-523f9a908a2a"
      },
      "source": [
        "X_test_scaled = pipeline_x_loaded.transform(X_test)\n",
        "y_test_scaled = pipeline_y_loaded.transform(y_test.values.reshape((-1,1)))\n",
        "\n",
        "X_test_scaled.astype('float32')\n",
        "y_test_scaled.astype('float32')\n",
        "\n",
        "# Concat features and target\n",
        "test_dataset = np.hstack((X_test_scaled, y_test_scaled))\n",
        "# convert into input/output\n",
        "X_test_split, y_test_split = split_sequences(test_dataset, n_steps_split)\n",
        "y_test_split = np.reshape(y_test_split, (-1, 1))\n",
        "# the dataset knows the number of features, e.g. 2\n",
        "n_features = X_test_split.shape[2]\n",
        "\n",
        "X_test_split = X_test_split.reshape((X_test_split.shape[0], n_seq, rows, n_steps, n_features))\n",
        "\n",
        "# Load model\n",
        "model = load_model('ConvLSTM2D_model.h5')\n",
        "yhat = model.predict(X_test_split)\n",
        "yhat = yhat.reshape((-1, 1)) # For TimeDistributed\n",
        "predicted = pipeline_y_loaded.inverse_transform(yhat)\n",
        "\n",
        "evaluation = model.evaluate(X_test_split, y_test_split)\n",
        "print('Model evaluation: ', evaluation)\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "256/256 [==============================] - 2s 9ms/step - loss: 0.0010 - mean_absolute_error: 0.0242\n",
            "Model evaluation:  [0.0010406547226011753, 0.024244222790002823]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3swDMY03nwO",
        "colab_type": "text"
      },
      "source": [
        "#### Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_bIYqnht2ps",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "outputId": "a3c881b2-aa64-460d-dc78-69a76099c993"
      },
      "source": [
        "# Predictions table\n",
        "df_predicted = pd.DataFrame()\n",
        "df_predicted['short_result'] = y_test.iloc[n_steps_split -1:]\n",
        "df_predicted['predictions'] = predicted\n",
        "#df_predicted = round(df_predicted,1)\n",
        "print(df_predicted.tail(20))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            short_result  predictions\n",
            "date                                 \n",
            "2020-08-03          -8.0     1.161044\n",
            "2020-08-04         -10.0     1.253905\n",
            "2020-08-05         -11.0     1.145322\n",
            "2020-08-06          -9.0     1.096220\n",
            "2020-08-07          -9.0     1.134565\n",
            "2020-08-10         -11.0     1.239049\n",
            "2020-08-11         -13.0     1.201077\n",
            "2020-08-12         -12.0     1.046481\n",
            "2020-08-13          -9.0     1.061645\n",
            "2020-08-14         -10.0     1.166229\n",
            "2020-08-17          -8.0     1.315403\n",
            "2020-08-18          -7.0     1.374941\n",
            "2020-08-19          -7.0     1.366565\n",
            "2020-08-20          -5.0     1.477423\n",
            "2020-08-21          -4.0     1.647661\n",
            "2020-08-24          -6.0     1.806118\n",
            "2020-08-25          -2.0     1.937590\n",
            "2020-08-26           1.0     1.981599\n",
            "2020-08-27           2.0     2.133734\n",
            "2020-08-28           0.0     2.290211\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArPaapu_t2vn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "d33fc767-c5dd-4f8e-827e-20bbb0a870a3"
      },
      "source": [
        "# Plot the predictions\n",
        "plt.plot(df_predicted.iloc[:100]);"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaivhA9Bt2tf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "06680097-fcb8-4925-cd15-71bd0262b6b3"
      },
      "source": [
        "# Analyse the values\n",
        "df_predicted.describe().T"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>short_result</th>\n",
              "      <td>8163.0</td>\n",
              "      <td>0.396055</td>\n",
              "      <td>7.473768</td>\n",
              "      <td>-40.000000</td>\n",
              "      <td>-4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>38.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>predictions</th>\n",
              "      <td>8163.0</td>\n",
              "      <td>0.831301</td>\n",
              "      <td>1.536608</td>\n",
              "      <td>-9.663687</td>\n",
              "      <td>-0.005914</td>\n",
              "      <td>0.830917</td>\n",
              "      <td>1.723635</td>\n",
              "      <td>6.779528</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               count      mean       std  ...       50%       75%        max\n",
              "short_result  8163.0  0.396055  7.473768  ...  0.000000  5.000000  38.000000\n",
              "predictions   8163.0  0.831301  1.536608  ...  0.830917  1.723635   6.779528\n",
              "\n",
              "[2 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ued60zkDgjAg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        },
        "outputId": "0f2d0429-7b0f-4fbb-9b9d-b46dab0c8962"
      },
      "source": [
        "# Metrics\n",
        "mse = round(mean_squared_error(y_test.iloc[n_steps_split -1:],predicted), 2)\n",
        "rmse = math.sqrt(mean_squared_error(y_test.iloc[n_steps_split -1:],predicted))\n",
        "mae = round(mean_absolute_error(y_test.iloc[n_steps_split -1:],predicted), 2)\n",
        "r2 = round(r2_score(y_test.iloc[n_steps_split -1:],predicted), 2) \n",
        "print('mse: ', mse)\n",
        "print('rmse: ', rmse)\n",
        "print('mae: ', mae)\n",
        "print('r2: ', r2)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mse:  58.85\n",
            "rmse:  7.67125909651661\n",
            "mae:  5.82\n",
            "r2:  -0.05\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}